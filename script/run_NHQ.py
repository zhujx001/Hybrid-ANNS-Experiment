#!/usr/bin/env python3
import os
import subprocess
import argparse

# ========= å›ºå®šè·¯å¾„ =========
BASE_DATA_PATH = "/data/HybridANNS/data"
SCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))
NHQ_PATH = os.path.join(SCRIPT_PATH, "../algorithm/NHQ-master")

LABEL_PATH = os.path.join(BASE_DATA_PATH, "Experiment/labelfilterData/labels")
QUERY_PATH = os.path.join(BASE_DATA_PATH, "Experiment/labelfilterData/query_label")
GROUNDTRUTH_PATH = os.path.join(BASE_DATA_PATH, "Experiment/labelfilterData/gt")
INDEX_PATH = os.path.join(BASE_DATA_PATH, "Experiment/Result/labelfilter/indexdata/NHQ")
# ä¿®æ­£æ•°æ®æ–‡ä»¶çš„è·¯å¾„
DATA_PATH = os.path.join(BASE_DATA_PATH, "Experiment/labelfilterData/datasets")

# ========= æ‰€æœ‰æ•°æ®é›†å‚æ•° =========
dataset_params = {
    "audio":      "K=100; L=130; ITER=12; S=10; R=100; RANGE=20; PL=250; B=0.6; M=1.0",
    "enron":      "K=100; L=100; ITER=12; S=10; R=100; RANGE=20; PL=50; B=0.2; M=1.0",
    "gist":       "K=100; L=100; ITER=12; S=10; R=300; RANGE=20; PL=50; B=0.6; M=1.0",
    "glove-100":  "K=100; L=100; ITER=12; S=10; R=100; RANGE=20; PL=150; B=0.2; M=1.0",
    "msong":      "K=400; L=420; ITER=12; S=10; R=300; RANGE=80; PL=150; B=0.6; M=1.0",
    "sift":       "K=100; L=100; ITER=12; S=10; R=300; RANGE=20; PL=350; B=0.4; M=1.0"
}

# ========= æŸ¥è¯¢é›†æ˜ å°„ =========
query_sets = {
    "1": "query_set_1", "2_1": "query_set_2_1", "2_2": "query_set_2_2",
    "3_1": "query_set_3_1", "3_2": "query_set_3_2", "3_3": "query_set_3_3", "3_4": "query_set_3_4",
    "4": "query_set_4", "5_1": "query_set_5_1", "5_2": "query_set_5_2", "5_3": "query_set_5_3", "5_4": "query_set_5_4",
    "6": "query_set_6",
   
}

# ========= å‚æ•°è§£æ =========
parser = argparse.ArgumentParser()
parser.add_argument("--datasets", nargs="+", help="Specify datasets (default: all)")
parser.add_argument("--queries", nargs="+", help="Specify query keys (default: all)")
args = parser.parse_args()

# ========= ç¼–è¯‘æ¨¡å— =========
def compile_all():
    import shutil

    # å®šä¹‰éœ€è¦æ¸…ç†çš„ build ç›®å½•
    clean_dirs = [
        "../algorithm/NHQ-master/NHQ-NPG_kgraph/build",
        "../algorithm/NHQ-master/NPG_kgraph/build"
    ]
    
    # å…ˆæ¸…ç†æ—§çš„ build ç›®å½•ï¼ˆé˜²æ­¢ CMakeCache.txt é”™è¯¯ï¼‰
    for build_dir in clean_dirs:
        abs_path = os.path.abspath(os.path.join(SCRIPT_PATH, build_dir))
        if os.path.exists(abs_path):
            print(f"ğŸ§¹ Removing old build directory: {abs_path}")
            shutil.rmtree(abs_path)

    # é‡æ–°æ‰§è¡Œæ„å»ºå‘½ä»¤
    cmds = [
        "cd ../algorithm/NHQ-master/NHQ-NPG_kgraph && mkdir -p build && cd build && cmake .. && make -j && cd ../../../..",
        "cd ../algorithm/NHQ-master/NHQ-NPG_nsw && make -j && cd examples/cpp && make -j && cd ../../../..",
        "cd ../algorithm/NHQ-master/NPG_kgraph && mkdir -p build && cd build && cmake .. && make -j && cd ../../../..",
        "cd ../algorithm/NHQ-master/NPG_nsw/n2 && make -j && cd examples/cpp && make -j && cd ../../../../.."
    ]

    for cmd in cmds:
        print(f"ğŸ› ï¸ {cmd}")
        subprocess.run(cmd, shell=True, check=True)

    print("âœ… Compilation completed\n")


# ========= æ„å»ºç´¢å¼• =========
def build_index(dataset, query_key):
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    base_vecs = os.path.join(DATA_PATH, dataset, f"{dataset}_base.fvecs")
    label_file = os.path.join(LABEL_PATH, dataset, f"label_{query_key.replace('_', '-')}.txt")
    
    # æ£€æŸ¥åŸºæœ¬æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.isfile(base_vecs):
        print(f"âŒ Base vector file not found: {base_vecs}")
        return False
    
    if not os.path.isfile(label_file):
        print(f"âŒ Label file not found: {label_file}")
        return False
    
    params = dict(x.split("=") for x in dataset_params[dataset].split("; "))
    index_dir = os.path.join(INDEX_PATH, f"NHQ_{dataset}_kgraph_{query_key.replace('_', '-')}")

    os.makedirs(index_dir, exist_ok=True)

    bin_path = os.path.join(NHQ_PATH, "NHQ-NPG_kgraph/build/tests/test_dng_index")
    
    # æ£€æŸ¥æ‰§è¡Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.isfile(bin_path):
        print(f"âŒ Binary file not found: {bin_path}")
        return False
    
    cmd = [
        "taskset", "-c", "0-31", bin_path,
        base_vecs, label_file,
        os.path.join(index_dir, "index"),
        os.path.join(index_dir, "table"),
        params["K"], params["L"], params["ITER"], params["S"], params["R"],
        params["RANGE"], params["PL"], params["B"], params["M"]
    ]
    print(f"ğŸ”¨ Building index: {dataset}, query {query_key}")
    print(f"ğŸ“¦ Command: {' '.join(str(c) for c in cmd)}\n")
    subprocess.run(cmd, check=True)
    return True

# ========= æ‰§è¡ŒæŸ¥è¯¢ =========
def search(dataset, query_key):
    base_file = os.path.join(DATA_PATH, dataset, f"{dataset}_base.fvecs")
    query_vecs = os.path.join(DATA_PATH, dataset, f"{dataset}_query.fvecs")
    label_file = os.path.join(QUERY_PATH, dataset, f"{query_key}.txt")
    gt_file = os.path.join(GROUNDTRUTH_PATH, dataset, f"gt-{query_sets[query_key]}.ivecs")
    index_dir = os.path.join(INDEX_PATH, f"NHQ_{dataset}_kgraph_{query_key.replace('_', '-')}")
    
    # æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶
    required_files = {
        "Base vector file": base_file,
        "Query vector file": query_vecs,
        "Label file": label_file,
        "Ground truth file": gt_file,
        "Index file": os.path.join(index_dir, "index"),
        "Table file": os.path.join(index_dir, "table")
    }
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_files = []
    for desc, file_path in required_files.items():
        if not os.path.isfile(file_path):
            missing_files.append(f"{desc}: {file_path}")
    
    # å¦‚æœæœ‰ç¼ºå¤±æ–‡ä»¶ï¼ŒæŠ¥å‘Šå¹¶è¿”å›
    if missing_files:
        print(f"âš ï¸ Missing files for {dataset}/{query_key}:")
        for missing in missing_files:
            print(f"   - {missing}")
        return False

    bin_path = os.path.join(NHQ_PATH, "NHQ-NPG_kgraph/build/tests/test_dng_optimized_search")
    
    # æ£€æŸ¥æ‰§è¡Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.isfile(bin_path):
        print(f"âŒ Binary file not found: {bin_path}")
        return False
    
    cmd = [bin_path,
           os.path.join(index_dir, "index"),
           os.path.join(index_dir, "table"),
           base_file, query_vecs, label_file, gt_file, dataset]

    print(f"ğŸ” Running search: {dataset}, query {query_key}")
    print(f"ğŸ“¦ Command: {' '.join(str(c) for c in cmd)}\n")
    subprocess.run(cmd, check=True)
    return True

# ========= ä¸»æµç¨‹ =========
if __name__ == "__main__":
    # compile_all()
    datasets = args.datasets if args.datasets else list(dataset_params.keys())
    queries = args.queries if args.queries else list(query_sets.keys())

    for dataset in datasets:
        if dataset not in dataset_params:
            print(f"âŒ Unknown dataset: {dataset}")
            continue
        for query_key in queries:
            if query_key not in query_sets:
                print(f"âŒ Unknown query: {query_key}")
                continue
            try:
                if build_index(dataset, query_key):
                    search(dataset, query_key)
                else:
                    print(f"âš ï¸ Skipping search for {dataset}, query {query_key} due to index build failure")
            except subprocess.CalledProcessError as e:
                print(f"âŒ Failed on {dataset}, query {query_key}: {e}")