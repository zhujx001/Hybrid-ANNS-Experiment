{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、创建表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "表 deep_range 创建成功！\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import struct\n",
    "\n",
    "# 1. 设置 PostgreSQL 连接\n",
    "def create_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            database=\"vectordb\",\n",
    "            user=\"vectordb\",\n",
    "            host=\"172.17.0.2\",  # depend on your own docker container ip\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"连接数据库失败: {e}\")\n",
    "        return None\n",
    "def create_table():\n",
    "    conn = create_connection()\n",
    "    if not conn:\n",
    "        print(\"无法连接到数据库，终止操作。\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS deep_range (\n",
    "            id int PRIMARY KEY,\n",
    "            image_embedding FLOAT8[] NOT NULL,\n",
    "            col_1 int NOT NULL\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"表 deep_range 创建成功！\")\n",
    "        cursor.close()\n",
    "    except Exception as e:\n",
    "        print(f\"创建表时出错: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、插入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import struct\n",
    "import os\n",
    "\n",
    "# 1. 设置 PostgreSQL 连接\n",
    "def create_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            database=\"vectordb\",\n",
    "            user=\"vectordb\",\n",
    "            host=\"172.17.0.2\",  # depend on your own docker container ip\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"连接数据库失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. 批量插入数据\n",
    "def insert_data(conn, batch_data):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        # 假设数据库表中有足够的列来接收 col_1 到 col_19\n",
    "        insert_query = \"INSERT INTO deep_range (id, image_embedding, col_1) VALUES (%s, %s, %s)\"\n",
    "        cursor.executemany(insert_query, batch_data)\n",
    "        conn.commit()\n",
    "        print(f\"成功插入 {len(batch_data)} 条数据！\")\n",
    "        cursor.close()\n",
    "    except Exception as e:\n",
    "        print(f\"插入数据时出错: {e}\")\n",
    "\n",
    "# 3. 读取文件并分批插入数据\n",
    "def load_and_insert_data(vector_file_path):\n",
    "    # 打开向量文件\n",
    "    with open(vector_file_path, \"rb\") as vector_file:\n",
    "        batch_data = []\n",
    "        id_counter = 0  # id 从 0 开始自增\n",
    "        batch_size = 1000  # 每批次插入1000条数据\n",
    "\n",
    "        # 创建数据库连接\n",
    "        conn = create_connection()\n",
    "        if not conn:\n",
    "            print(\"无法连接到数据库，终止操作。\")\n",
    "            return\n",
    "\n",
    "        while True:\n",
    "            # 读取向量数据\n",
    "            dim_bytes = vector_file.read(4)\n",
    "            if not dim_bytes:\n",
    "                break  # 文件结束\n",
    "            dim = struct.unpack('i', dim_bytes)[0]\n",
    "            vector = struct.unpack('f' * dim, vector_file.read(4 * dim))\n",
    "\n",
    "            # 将解析后的数据追加到批量数据列表\n",
    "            batch_data.append((id_counter, list(vector), id_counter))\n",
    "\n",
    "            # 检查是否达到批量大小，如果是，则插入数据库并清空批量数据列表\n",
    "            if len(batch_data) == batch_size:\n",
    "                insert_data(conn, batch_data)\n",
    "                batch_data = []\n",
    "\n",
    "            id_counter += 1\n",
    "\n",
    "        # 插入剩余的批量数据\n",
    "        if batch_data:\n",
    "            insert_data(conn, batch_data)\n",
    "\n",
    "        conn.close()  # 关闭数据库连接\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/Experiment\"))\n",
    "# 4. 执行数据加载和插入\n",
    "vector_file_path = os.path.join(ROOT_DIR, \"rangefilterData/datasets/deep/deep_base.fvecs\")\n",
    "load_and_insert_data(vector_file_path)\n",
    "\n",
    "print(\"数据导入完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、计算索引构建时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "连接成功！\n",
      "索引构建完成！\n",
      "索引构建时间: 438.92 秒\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "import time\n",
    "import gc\n",
    "import resource\n",
    "import os\n",
    "\n",
    "# 创建数据库连接\n",
    "def create_connection():\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            database=\"vectordb\",\n",
    "            user=\"vectordb\",\n",
    "            host=\"172.17.0.2\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        print(\"连接成功！\")\n",
    "    except OperationalError as e:\n",
    "        print(f\"连接失败: {e}\")\n",
    "    return conn\n",
    "\n",
    "# 执行索引构建SQL\n",
    "def create_index(conn):\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        # 禁用垃圾回收\n",
    "        gc.disable()\n",
    "        \n",
    "        # 记录开始时间\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 获取索引构建前的内存占用\n",
    "        start_memory = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "        # 执行索引构建\n",
    "        create_index_sql = \"\"\"\n",
    "            CREATE INDEX vbase_deep_16_200\n",
    "            ON deep_range\n",
    "            USING hnsw(image_embedding)\n",
    "            WITH (\n",
    "                dimension = 96,\n",
    "                distmethod = 'l2_distance'\n",
    "            );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_index_sql)\n",
    "        conn.commit()  # 提交事务\n",
    "\n",
    "        # 获取索引构建后的内存占用\n",
    "        end_memory = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "        \n",
    "        # 记录结束时间\n",
    "        end_time = time.time()\n",
    "        index_build_time = end_time - start_time\n",
    "\n",
    "        print(f\"索引构建完成！\")\n",
    "        print(f\"索引构建时间: {index_build_time:.2f} 秒\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"索引构建失败: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def main():\n",
    "    # 创建数据库连接\n",
    "    connection = create_connection()\n",
    "\n",
    "    if connection:\n",
    "        try:\n",
    "            create_index(connection)\n",
    "\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、脚本单线程搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import struct\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 1. 设置 PostgreSQL 连接\n",
    "def create_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            database=\"vectordb\",\n",
    "            user=\"vectordb\",\n",
    "            host=\"172.17.0.2\",  # 你的数据库主机\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"连接数据库失败: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_fvecs_file(file_path):\n",
    "    \"\"\"读取 .fvecs 文件并返回所有向量\"\"\"\n",
    "    query_vectors = []\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        while True:\n",
    "            # 读取向量维度\n",
    "            dim_bytes = f.read(4)\n",
    "            if not dim_bytes:\n",
    "                break\n",
    "            dim = struct.unpack('i', dim_bytes)[0]\n",
    "            # 读取向量数据\n",
    "            vector_bytes = f.read(dim * 4)\n",
    "            if not vector_bytes:\n",
    "                break\n",
    "            vector = struct.unpack(f'{dim}f', vector_bytes)\n",
    "            query_vectors.append(vector)\n",
    "    return query_vectors\n",
    "\n",
    "def read_range_file(file_path):\n",
    "    \"\"\"读取范围文件并返回范围列表\"\"\"\n",
    "    ranges = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:  # 跳过空行\n",
    "                start, end = map(int, line.split())  # 假设范围文件每行是 \"start end\"\n",
    "                ranges.append((start, end))\n",
    "    return ranges\n",
    "\n",
    "def execute_query(conn, query, params, output_file, j_value, total_time, k):\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"SET enable_seqscan = off;\")  # 设置索引扫描\n",
    "        cursor.execute(\"SET enable_indexscan = on;\")  # 设置索引扫描\n",
    "        cursor.execute(f\"SET hnsw.ef_search = {j_value};\")  # 设置索引扫描\n",
    "        # 设置索引扫描和关闭顺序扫描\n",
    "        start_time = time.time()  # 开始计时\n",
    "        # 执行查询\n",
    "        cursor.execute(query, params)\n",
    "        result = cursor.fetchall()  # 获取查询结果\n",
    "        end_time = time.time()  # 结束计时\n",
    "        print(f\"查询执行时间: {end_time - start_time:.6f} 秒\")\n",
    "        if k != 0:\n",
    "            total_time += (end_time - start_time)  # 累加查询时间\n",
    "\n",
    "        # 将查询结果写入文件\n",
    "        with open(output_file, \"a\") as f:\n",
    "            ids = [str(row[0] - 1) for row in result]  # 提取 ID 列\n",
    "            f.write(\" \".join(ids) + \"\\n\")  # 每次查询结果写在一行\n",
    "    except Exception as e:\n",
    "        print(f\"查询失败: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "    return total_time\n",
    "\n",
    "def main():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/Experiment\"))\n",
    "    # 文件路径\n",
    "    fvecs_file = os.path.join(ROOT_DIR, \"rangefilterData/datasets/deep/deep_query.fvecs\")\n",
    "\n",
    "    list_1 = [\"2\", \"8\"]\n",
    "    list_3 = [20, 30, 50, 86, 150, 250, 400, 500]\n",
    "\n",
    "    # 读取向量数据\n",
    "    query_vectors = read_fvecs_file(fvecs_file)\n",
    "\n",
    "    for i_value in list_1:\n",
    "        for j_value in list_3:\n",
    "            # 创建数据库连接\n",
    "            connection = create_connection()\n",
    "            if connection:\n",
    "                try:\n",
    "                    # 根据 i_value 确定范围文件路径\n",
    "                    if i_value == \"2\":\n",
    "                        range_file = os.path.join(ROOT_DIR, \"rangefilterData/query_range/deep/deep-96-euclidean_queries_2pow-2_ranges.txt\")\n",
    "                    elif i_value == \"8\":\n",
    "                        range_file = os.path.join(ROOT_DIR, \"rangefilterData/query_range/deep/deep-96-euclidean_queries_2pow-8_ranges.txt\")\n",
    "                    else:\n",
    "                        print(f\"未知的范围文件类型: {i_value}\")\n",
    "                        continue\n",
    "\n",
    "                    output_file = os.path.join(os.getcwd(), \"result\", f\"{i_value}_16_200_{j_value}.out\")\n",
    "                    ranges = read_range_file(range_file)\n",
    "                    # 清空结果文件，确保每次执行时写入的是最新的查询结果\n",
    "                    with open(output_file, \"w\") as f:\n",
    "                        f.truncate(0)\n",
    "\n",
    "                    total_time = 0\n",
    "                    # 遍历范围\n",
    "                    for k, (start, end) in enumerate(ranges):\n",
    "                        query_vector = query_vectors[k]\n",
    "                        # 构造 SQL 查询语句\n",
    "                        query = f\"\"\"\n",
    "                            SELECT id, image_embedding <-> ARRAY[{', '.join(map(str, query_vector))}] AS distance\n",
    "                            FROM deep_range\n",
    "                            WHERE col_1 BETWEEN %s AND %s\n",
    "                            ORDER BY distance\n",
    "                            LIMIT 10;\n",
    "                        \"\"\"\n",
    "                        print(f\"正在执行范围查询: {start} 到 {end}...\")\n",
    "                        total_time = execute_query(connection, query, (start, end), output_file, j_value, total_time, k)\n",
    "                    qps = len(query_vectors) / total_time if total_time != 0 else 0\n",
    "                    # 将 QPS 写入 output_file\n",
    "                    with open(output_file, \"a\") as f:  # 使用追加模式\n",
    "                        f.write(f\"\\nQPS: {qps}\\n\")\n",
    "                finally:\n",
    "                    connection.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、脚本计算召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_ivecs(fname):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        data = []\n",
    "        while True:\n",
    "            try:\n",
    "                # Read the dimension\n",
    "                width = np.fromfile(f, 'int32', 1)[0]\n",
    "                \n",
    "                # Read the vector data\n",
    "                vector = np.fromfile(f, 'int32', width)\n",
    "                \n",
    "                # If the vector is longer than 10, we only take the first 10 elements\n",
    "                data.append(vector[:10])\n",
    "            except IndexError:\n",
    "                break  # End of file\n",
    "\n",
    "    return np.array(data)\n",
    "def read_txt(fname):\n",
    "    \"\"\"读取以空格分隔的文本文件，每行包含10个元素\"\"\"\n",
    "    with open(fname, \"r\") as f:\n",
    "        data = []\n",
    "        for line in f:\n",
    "            # 将每行的数字解析为整数列表\n",
    "            vector = list(map(int, line.strip().split()))\n",
    "            data.append(vector[:10])  # 每行只取前10个元素\n",
    "    return np.array(data)\n",
    "\n",
    "def read_output_file(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        lines = f.readlines()  # 读取所有行\n",
    "        if len(lines) > 2:  # 如果文件行数大于2，忽略最后两行\n",
    "            lines = lines[:-2]\n",
    "        return [list(map(int, line.split())) for line in lines]\n",
    "\n",
    "def extract_qps(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            last_line = lines[-1].strip()  # 获取最后一行并去除首尾空格\n",
    "            if \"QPS:\" in last_line:\n",
    "                qps_value = last_line.split(\"QPS:\")[-1].strip()  # 提取 QPS 值\n",
    "                return qps_value\n",
    "    return \"N/A\"  # 如果没有找到 QPS 值，返回 N/A\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/Experiment\"))\n",
    "recall_file = os.path.join(os.getcwd(), \"result\", f\"single_qps.out\")\n",
    "# 打开文件用于写入结果\n",
    "with open(recall_file, \"a\") as output_file:\n",
    "    list_1 = [\"2\", \"8\"]\n",
    "    list_2 = [20, 30, 50, 86, 150, 250, 400, 500]\n",
    "\n",
    "    for i_value in list_1:\n",
    "        for j_value in list_2:\n",
    "            # Read ground truth\n",
    "            gt_file = os.path.join(ROOT_DIR, f\"rangefilterData/gt/deep/gt-query_set_{i_value}.ivecs\")\n",
    "            gt_data = read_ivecs(gt_file)\n",
    "\n",
    "            # Read result file\n",
    "            result_file = os.path.join(os.getcwd(), \"result\", f\"{i_value}_16_200_{j_value}.out\")\n",
    "            result_data = read_output_file(result_file)\n",
    "\n",
    "            # Extract QPS value\n",
    "            qps_value = extract_qps(result_file)\n",
    "\n",
    "            # Calculate recall\n",
    "            total_queries = len(gt_data)\n",
    "            correct_matches = 0\n",
    "\n",
    "            # For each query in ground truth\n",
    "            for i, gt_row in enumerate(gt_data):\n",
    "                # Check if any of the first 10 elements from ground truth are in the result's top 10\n",
    "                # correct_matches += sum(1 for gt_val in gt_row if gt_val in result_data[i][:10])\n",
    "                # 将结果文件的值加 1 后再与 ground truth 比较\n",
    "                result_row = [val + 1 for val in result_data[i][:10]]\n",
    "                correct_matches += sum(1 for gt_val in gt_row if gt_val in result_row)\n",
    "\n",
    "            # Recall calculation\n",
    "            recall = correct_matches / (total_queries * 10)  # Since each query has 10 elements to match\n",
    "\n",
    "            # 写入结果到文件\n",
    "            output_file.write(f\"Recall Rate {i_value:<6} and {j_value:<4}: {recall:>6.4f}, QPS: {float(qps_value):>8.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
